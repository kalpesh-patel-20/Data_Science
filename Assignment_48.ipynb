{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1. What is Lasso Regression, and how does it differ from other regression techniques?**\n",
        "\n",
        "**Lasso Regression** (Least Absolute Shrinkage and Selection Operator) is a linear regression technique that uses **L1 regularization**.  \n",
        "It adds a penalty equal to the **absolute value** of the coefficients to the loss function.\n",
        "\n",
        "This encourages the model to **shrink some coefficients to exactly zero**, effectively performing **feature selection**.\n",
        "\n",
        "➡️ **Difference from other techniques**:\n",
        "- **OLS Regression**: No penalty term.\n",
        "- **Ridge Regression**: L2 penalty (squares of coefficients, shrinks but doesn’t zero them).\n",
        "- **Lasso**: L1 penalty (absolute values, can shrink coefficients to **zero**).\n",
        "\n",
        "---\n",
        "\n",
        "### **Q2. What is the main advantage of using Lasso Regression in feature selection?**\n",
        "\n",
        "Lasso can **automatically eliminate less important features** by setting their coefficients to **zero**.\n",
        "\n",
        "➡️ This helps:\n",
        "- Reduce model complexity\n",
        "- Improve interpretability\n",
        "- Handle high-dimensional data effectively\n",
        "\n",
        "---\n",
        "\n",
        "### **Q3. How do you interpret the coefficients of a Lasso Regression model?**\n",
        "\n",
        "Similar to linear regression:\n",
        "- Each coefficient shows the impact of a one-unit increase in the feature on the target.\n",
        "\n",
        "However:\n",
        "- Some coefficients may be **exactly zero** → these features are considered **irrelevant** to the model.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q4. What are the tuning parameters in Lasso Regression, and how do they affect performance?**\n",
        "\n",
        "The main tuning parameter is **lambda (λ)**, often called **alpha** in libraries like scikit-learn.\n",
        "\n",
        "- A **higher lambda** → stronger regularization → more coefficients shrink to zero.\n",
        "- A **lower lambda** → model behaves more like ordinary least squares (less shrinkage).\n",
        "\n",
        "➡️ **Trade-off**:\n",
        "- Too high → underfitting\n",
        "- Too low → overfitting\n",
        "\n",
        "---\n",
        "\n",
        "### **Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?**\n",
        "\n",
        "Yes, but indirectly.\n",
        "\n",
        "- **Lasso is inherently linear**, but you can create **non-linear features** manually (like polynomial or interaction terms).\n",
        "- Then apply Lasso on the transformed features.\n",
        "\n",
        "➡️ This allows it to model non-linear relationships using a linear approach on engineered features.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q6. What is the difference between Ridge Regression and Lasso Regression?**\n",
        "\n",
        "| Feature | Ridge | Lasso |\n",
        "|--------|-------|-------|\n",
        "| Penalty | L2 (squared) | L1 (absolute) |\n",
        "| Coefficient shrinkage | Shrinks close to zero | Shrinks to **zero** |\n",
        "| Feature selection | ❌ No | ✅ Yes |\n",
        "| Handles multicollinearity | ✅ Yes | ✅ Yes (selects one of the correlated features) |\n",
        "\n",
        "---\n",
        "\n",
        "### **Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?**\n",
        "\n",
        "Yes.\n",
        "\n",
        "- Lasso handles multicollinearity by **selecting one feature** among highly correlated ones and **ignoring the rest** (setting their coefficients to zero).\n",
        "- This helps simplify the model and reduce overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?**\n",
        "\n",
        "Use **cross-validation**:\n",
        "\n",
        "- Techniques like **K-Fold Cross-Validation** with a **grid of lambda values**.\n",
        "- Tools like `LassoCV` in scikit-learn automatically find the best lambda by testing multiple values.\n",
        "\n",
        "➡️ Choose the value that **minimizes the validation error**.\n"
      ],
      "metadata": {
        "id": "7JIRFuJk6XLQ"
      }
    }
  ]
}