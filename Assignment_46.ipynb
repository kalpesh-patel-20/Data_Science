{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is R-squared in Linear Regression?\n",
        "\n",
        "R-squared (also called the coefficient of determination) tells us how much of the variation in the dependent variable can be explained by the independent variables in the model.\n",
        "\n",
        "**How it’s calculated**:  \n",
        "R-squared = 1 - (SS_res / SS_total)  \n",
        "- SS_res = sum of squared residuals (errors)  \n",
        "- SS_total = total sum of squares (total variation)\n",
        "\n",
        "**What it means**:  \n",
        "An R-squared of 0.80 means 80% of the variation in the output can be explained by the model.\n",
        "\n",
        "---\n",
        "\n",
        "### Q2. What is Adjusted R-squared?\n",
        "\n",
        "Adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in the model. It increases only if the new predictor improves the model more than expected by chance.\n",
        "\n",
        "**Why it’s useful**:  \n",
        "Unlike R-squared, adjusted R-squared doesn’t always go up when more variables are added. It can decrease if the new variable doesn't help much.\n",
        "\n",
        "---\n",
        "\n",
        "### Q3. When to Use Adjusted R-squared?\n",
        "\n",
        "Use **adjusted R-squared** when comparing models with a different number of independent variables. It helps avoid overfitting by penalizing unnecessary variables.\n",
        "\n",
        "---\n",
        "\n",
        "### Q4. What are RMSE, MSE, and MAE?\n",
        "\n",
        "These are evaluation metrics used to measure prediction errors in regression:\n",
        "\n",
        "- **MAE (Mean Absolute Error)**: Average of absolute errors.  \n",
        "  Formula: sum(abs(actual - predicted)) / n\n",
        "\n",
        "- **MSE (Mean Squared Error)**: Average of squared errors.  \n",
        "  Formula: sum((actual - predicted)^2) / n\n",
        "\n",
        "- **RMSE (Root Mean Squared Error)**: Square root of MSE.  \n",
        "  Formula: sqrt(MSE)\n",
        "\n",
        "---\n",
        "\n",
        "### Q5. Advantages and Disadvantages of RMSE, MSE, MAE\n",
        "\n",
        "- **MAE**:\n",
        "  - + Easy to understand\n",
        "  - – Treats all errors equally\n",
        "\n",
        "- **MSE**:\n",
        "  - + Penalizes large errors more (useful if big mistakes are worse)\n",
        "  - – Not interpretable in original units\n",
        "\n",
        "- **RMSE**:\n",
        "  - + Penalizes large errors, and result is in original units\n",
        "  - – Sensitive to outliers\n",
        "\n",
        "---\n",
        "\n",
        "### Q6. What is Lasso Regularization?\n",
        "\n",
        "Lasso (Least Absolute Shrinkage and Selection Operator) adds a penalty equal to the **absolute** value of the coefficients to the loss function.\n",
        "\n",
        "**Key difference from Ridge**:\n",
        "- **Lasso** can shrink some coefficients to zero (feature selection).\n",
        "- **Ridge** shrinks them towards zero but never exactly zero.\n",
        "\n",
        "Use **Lasso** when you want to remove unnecessary features.\n",
        "\n",
        "---\n",
        "\n",
        "### Q7. How Do Regularized Models Prevent Overfitting?\n",
        "\n",
        "Regularized models add a penalty to the loss function to reduce model complexity. This discourages the model from fitting noise in the training data.\n",
        "\n",
        "**Example**: In a dataset with many predictors, Lasso can drop irrelevant ones, and Ridge can reduce the impact of less useful features.\n",
        "\n",
        "---\n",
        "\n",
        "### Q8. Limitations of Regularized Linear Models\n",
        "\n",
        "- Might not perform well on **non-linear relationships** unless combined with polynomial features.\n",
        "- Choosing the right **regularization strength (alpha)** requires tuning.\n",
        "- **Lasso** might drop too many features if alpha is too high.\n",
        "- **Ridge** can’t perform feature selection.\n",
        "\n",
        "---\n",
        "\n",
        "### Q9. Comparing Model A (RMSE = 10) and Model B (MAE = 8)\n",
        "\n",
        "You can’t directly compare RMSE and MAE values unless both are calculated for the same model.\n",
        "\n",
        "But generally:\n",
        "- If MAE is much lower, it means fewer big errors.\n",
        "- RMSE emphasizes large errors more than MAE.\n",
        "\n",
        "**Limitations**: RMSE might look worse even if most predictions are good but a few are really bad. MAE is more stable.\n",
        "\n",
        "Best approach: compare both metrics **on both models**, not one per model.\n",
        "\n",
        "---\n",
        "\n",
        "### Q10. Comparing Ridge (Model A) vs Lasso (Model B)\n",
        "\n",
        "- **Model A** uses Ridge (alpha = 0.1)\n",
        "- **Model B** uses Lasso (alpha = 0.5)\n",
        "\n",
        "If Lasso improves performance **and reduces model complexity** by removing irrelevant features, it might be preferred.\n",
        "\n",
        "**Trade-offs**:\n",
        "- Lasso may ignore important but weak predictors.\n",
        "- Ridge keeps all features, useful if all have some contribution.\n",
        "\n",
        "Final decision depends on:\n",
        "- Model accuracy on test data\n",
        "- Need for feature selection\n",
        "- Simplicity vs completeness\n"
      ],
      "metadata": {
        "id": "Jq27mBDJ4W5-"
      }
    }
  ]
}