{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. **What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.**\n",
        "\n",
        "ANS:\n",
        "**Web Scraping** is the process of automatically extracting data from websites. It involves retrieving the website content and parsing it to extract the desired information for further analysis or storage.\n",
        "\n",
        "**Why is it Used?**\n",
        "Web scraping is used to:\n",
        "- Gather large amounts of data efficiently.\n",
        "- Automate data collection tasks.\n",
        "- Obtain real-time data for analysis or decision-making.\n",
        "\n",
        "**Three Areas Where Web Scraping is Used:**\n",
        "1. **E-commerce:** To monitor competitors' pricing, product availability, and customer reviews.\n",
        "2. **Real Estate:** To gather property listings, prices, and trends from various real estate websites.\n",
        "3. **Market Research:** To analyze customer sentiments, trends, and product demand by extracting social media data or product reviews.\n",
        "\n",
        "---\n",
        "\n",
        "### Q2. **What are the Different Methods Used for Web Scraping?**\n",
        "ANS: Different Methods are:\n",
        "1. **Manual Scraping:** Manually copying and pasting data from a website.\n",
        "2. **Using APIs:** Accessing structured data through APIs provided by websites.\n",
        "3. **Automated Tools:** Employing web scraping libraries and tools such as Beautiful Soup, Scrapy, or Selenium.\n",
        "4. **Browser Extensions:** Using browser plugins to extract data (e.g., Web Scraper Chrome extension).\n",
        "5. **HTTP Libraries:** Using HTTP request libraries like `requests` to fetch raw HTML and parse it.\n",
        "\n",
        "---\n",
        "\n",
        "### Q3. **What is Beautiful Soup? Why is it Used?**\n",
        "\n",
        "ANS:\n",
        "**Beautiful Soup** is a Python library used for parsing HTML and XML documents. It creates a parse tree from page source code, enabling efficient navigation, searching, and modification of the HTML content.\n",
        "\n",
        "**Why is it Used?**\n",
        "- To extract specific data elements from websites, such as titles, links, or tables.\n",
        "- To navigate complex HTML structures using tags, attributes, and CSS selectors.\n",
        "- To clean and preprocess web data for analysis or storage.\n",
        "\n",
        "---\n",
        "\n",
        "### Q4. **Why is Flask Used in This Web Scraping Project?**\n",
        "\n",
        "ANS:\n",
        "Flask is a lightweight web framework for Python, and it is used in this project because:\n",
        "1. **Simplicity:** Flask provides an easy way to create web applications or APIs for serving scraped data.\n",
        "2. **Integration:** It integrates well with Python libraries like Beautiful Soup, allowing seamless data processing.\n",
        "3. **Dynamic Content:** Flask enables building dynamic and interactive web pages or dashboards to display scraped data.\n",
        "4. **Flexibility:** It supports customization and scalability for different project requirements.\n",
        "\n",
        "---\n",
        "\n",
        "### Q5. **Write the Names of AWS Services Used in This Project. Also, Explain the Use of Each Service.**\n",
        "\n",
        "ANS:\n",
        "The specific AWS services used depend on the project setup. Commonly used AWS services for web scraping projects include:\n",
        "\n",
        "1. **Amazon EC2 (Elastic Compute Cloud):**\n",
        "   - Used to host and run the web scraping scripts and the Flask application on virtual servers.\n",
        "\n",
        "2. **AWS Lambda:**\n",
        "   - Used for serverless execution of scraping scripts triggered on-demand or on a schedule.\n",
        "\n",
        "3. **Amazon S3 (Simple Storage Service):**\n",
        "   - Stores scraped data, logs, or other resources for later use or analysis.\n",
        "\n",
        "4. **Amazon RDS (Relational Database Service):**\n",
        "   - Stores and manages structured data collected from web scraping in a scalable and managed relational database.\n",
        "\n",
        "5. **AWS CloudWatch:**\n",
        "   - Monitors scraping jobs and logs for performance, errors, or irregularities.\n",
        "\n",
        "These services work together to ensure the efficient execution, storage, and management of data in a web scraping project."
      ],
      "metadata": {
        "id": "9j-THvVOYSrK"
      }
    }
  ]
}