{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ **Q1. Import the dataset and explore it**\n",
        "\n",
        "### **Code outline (in Python using Pandas, Matplotlib, Seaborn):**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"diabetes.csv\")  # replace with the actual file path if local\n",
        "\n",
        "# Preview the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Check for nulls\n",
        "print(df.info())\n",
        "\n",
        "# Visualizations\n",
        "sns.pairplot(df, hue='Outcome')\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Q2. Data preprocessing**\n",
        "\n",
        "### Tasks:\n",
        "- Handle missing or zero values (especially in `Glucose`, `BMI`, `BloodPressure`, `SkinThickness`, and `Insulin`)\n",
        "- Outlier removal using IQR or z-score\n",
        "- No categorical variables → dummy encoding not needed\n",
        "\n",
        "```python\n",
        "# Replace 0 with NaN for relevant columns (except 'Pregnancies' and 'Outcome')\n",
        "cols_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_zeros] = df[cols_with_zeros].replace(0, pd.NA)\n",
        "\n",
        "# Fill missing values with median\n",
        "for col in cols_with_zeros:\n",
        "    df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "# Check again\n",
        "print(df.isnull().sum())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Q3. Train-test split**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(\"Outcome\", axis=1)\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Q4. Train Decision Tree with Cross-validation**\n",
        "\n",
        "Use `GridSearchCV` with DecisionTreeClassifier.\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"max_depth\": [3, 5, 7, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Q5. Evaluate model performance**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "\n",
        "# ROC Curve\n",
        "y_proba = clf.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_proba):.2f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Q6. Interpret the decision tree**\n",
        "\n",
        "```python\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(clf.best_estimator_, feature_names=X.columns, class_names=[\"No Diabetes\", \"Diabetes\"], filled=True)\n",
        "plt.show()\n",
        "\n",
        "# Feature importances\n",
        "importances = pd.Series(clf.best_estimator_.feature_importances_, index=X.columns)\n",
        "importances.sort_values(ascending=False).plot(kind='bar', title=\"Feature Importance\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Likely top features:\n",
        "- Glucose\n",
        "- BMI\n",
        "- Age\n",
        "- Insulin\n",
        "\n",
        "You can interpret splits like:  \n",
        "> If Glucose > 127 and BMI > 30 → high likelihood of diabetes.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ **Q7. Validate the model (robustness check)**\n",
        "\n",
        "You can simulate new data scenarios or perturb values:\n",
        "\n",
        "```python\n",
        "# Sensitivity test: Add small noise to test data\n",
        "import numpy as np\n",
        "X_test_perturbed = X_test.copy()\n",
        "X_test_perturbed += np.random.normal(0, 0.01, X_test.shape)\n",
        "y_pred_perturbed = clf.predict(X_test_perturbed)\n",
        "\n",
        "# Compare results\n",
        "print(\"Original F1:\", classification_report(y_test, y_pred, output_dict=True)[\"weighted avg\"][\"f1-score\"])\n",
        "print(\"Perturbed F1:\", classification_report(y_test, y_pred_perturbed, output_dict=True)[\"weighted avg\"][\"f1-score\"])\n",
        "```\n"
      ],
      "metadata": {
        "id": "JYSHUaYpGLkM"
      }
    }
  ]
}