{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Difference between Simple Linear Regression and Multiple Linear Regression\n",
        "\n",
        "- **Simple Linear Regression** involves one independent variable and one dependent variable.  \n",
        "  **Example**: Predicting a student’s exam score based on hours studied.\n",
        "\n",
        "- **Multiple Linear Regression** uses two or more independent variables to predict a dependent variable.  \n",
        "  **Example**: Predicting house price based on size, number of bedrooms, and location.\n",
        "\n",
        "---\n",
        "\n",
        "### Q2. Assumptions of Linear Regression\n",
        "\n",
        "1. **Linearity**: The relationship between the independent and dependent variable is linear.\n",
        "2. **Independence**: Observations are independent of each other.\n",
        "3. **Homoscedasticity**: Constant variance of errors.\n",
        "4. **Normality of residuals**: Errors should be normally distributed.\n",
        "5. **No multicollinearity** (in multiple regression): Independent variables should not be highly correlated.\n",
        "\n",
        "**How to check**:\n",
        "- Plot residuals vs fitted values for homoscedasticity and linearity.\n",
        "- Use correlation matrix or VIF (Variance Inflation Factor) for multicollinearity.\n",
        "- Use histogram or Q-Q plot for normality of residuals.\n",
        "- Durbin-Watson test for independence of residuals.\n",
        "\n",
        "---\n",
        "\n",
        "### Q3. Interpreting Slope and Intercept\n",
        "\n",
        "- **Slope**: Shows how much the dependent variable changes for each one-unit increase in the independent variable.\n",
        "- **Intercept**: The value of the dependent variable when the independent variable is zero.\n",
        "\n",
        "**Example**:  \n",
        "In a model predicting salary based on years of experience:  \n",
        "Salary = 30000 + 2000 * Years  \n",
        "- Intercept (30000): Base salary with 0 years of experience  \n",
        "- Slope (2000): Each additional year increases salary by 2000\n",
        "\n",
        "---\n",
        "\n",
        "### Q4. What is Gradient Descent?\n",
        "\n",
        "Gradient descent is an optimization algorithm used to minimize the error (or cost) in a machine learning model. It updates the model’s parameters (like weights in regression) in small steps in the direction that reduces the error the most. It’s widely used to train models like linear regression and neural networks.\n",
        "\n",
        "---\n",
        "\n",
        "### Q5. What is Multiple Linear Regression?\n",
        "\n",
        "Multiple linear regression is a model that uses two or more independent variables to predict one dependent variable.  \n",
        "It fits a plane or hyperplane instead of a line.  \n",
        "It differs from simple linear regression in the number of inputs and the model's ability to capture more complex relationships.\n",
        "\n",
        "---\n",
        "\n",
        "### Q6. What is Multicollinearity?\n",
        "\n",
        "Multicollinearity occurs when independent variables in a regression model are highly correlated with each other. This can make the coefficients unreliable.\n",
        "\n",
        "**Detection**:\n",
        "- Check the correlation matrix.\n",
        "- Calculate VIF (values above 5 or 10 indicate issues).\n",
        "\n",
        "**How to fix**:\n",
        "- Remove or combine correlated variables.\n",
        "- Use regularization techniques like Ridge or Lasso regression.\n",
        "\n",
        "---\n",
        "\n",
        "### Q7. What is Polynomial Regression?\n",
        "\n",
        "Polynomial regression is a type of regression that models the relationship between the dependent and independent variable as an nth-degree polynomial.  \n",
        "It is used when the data shows a curved (non-linear) trend that cannot be captured by linear regression.\n",
        "\n",
        "---\n",
        "\n",
        "### Q8. Advantages and Disadvantages of Polynomial Regression\n",
        "\n",
        "**Advantages**:\n",
        "- Can model non-linear relationships.\n",
        "- More flexible than linear regression.\n",
        "\n",
        "**Disadvantages**:\n",
        "- Can overfit the data, especially with high-degree polynomials.\n",
        "- Less interpretable.\n",
        "\n",
        "**Use it when**:\n",
        "- The relationship between variables is curved.\n",
        "- Linear regression doesn't provide good fit based on residual plots or accuracy metrics.\n"
      ],
      "metadata": {
        "id": "EOp6eM8P22Ca"
      }
    }
  ]
}