{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Write a Python program to extract the video URL of the first five videos.\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "video_urls = []\n",
        "videos = soup.find_all('ytd-grid-video-renderer', limit=5)\n",
        "\n",
        "for video in videos:\n",
        "    video_url = 'https://www.youtube.com' + video.find('a', {'id': 'video-title'})['href']\n",
        "    video_urls.append(video_url)\n",
        "\n",
        "# Displaying the extracted video URLs\n",
        "for url in video_urls:\n",
        "    print(url)\n",
        "```\n",
        "\n",
        "### Q2. Write a Python program to extract the URL of the video thumbnails of the first five videos.\n",
        "```python\n",
        "thumbnail_urls = []\n",
        "\n",
        "for video in videos:\n",
        "    thumbnail_url = video.find('img')['src']\n",
        "    thumbnail_urls.append(thumbnail_url)\n",
        "\n",
        "# Displaying the extracted thumbnail URLs\n",
        "for url in thumbnail_urls:\n",
        "    print(url)\n",
        "```\n",
        "\n",
        "### Q3. Write a Python program to extract the title of the first five videos.\n",
        "```python\n",
        "titles = []\n",
        "\n",
        "for video in videos:\n",
        "    title = video.find('a', {'id': 'video-title'}).text.strip()\n",
        "    titles.append(title)\n",
        "\n",
        "# Displaying the extracted video titles\n",
        "for title in titles:\n",
        "    print(title)\n",
        "```\n",
        "\n",
        "### Q4. Write a Python program to extract the number of views of the first five videos.\n",
        "```python\n",
        "views = []\n",
        "\n",
        "for video in videos:\n",
        "    views_text = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text.strip()\n",
        "    views.append(views_text)\n",
        "\n",
        "# Displaying the extracted views\n",
        "for view in views:\n",
        "    print(view)\n",
        "```\n",
        "\n",
        "### Q5. Write a Python program to extract the time of posting of video for the first five videos.\n",
        "```python\n",
        "post_times = []\n",
        "\n",
        "for video in videos:\n",
        "    post_time = video.find('div', {'id': 'metadata-line'}).find_all('span')[1].text.strip()\n",
        "    post_times.append(post_time)\n",
        "\n",
        "# Displaying the extracted posting times\n",
        "for post_time in post_times:\n",
        "    print(post_time)\n",
        "```\n",
        "\n",
        "### Save All the Data Scraped in a CSV File:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Combining the extracted data into a dictionary\n",
        "data = {\n",
        "    'Video URL': video_urls,\n",
        "    'Thumbnail URL': thumbnail_urls,\n",
        "    'Title': titles,\n",
        "    'Views': views,\n",
        "    'Post Time': post_times\n",
        "}\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Saving to CSV\n",
        "df.to_csv('youtube_video_data.csv', index=False)\n",
        "print(\"Data saved to youtube_video_data.csv\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7skzUvF-2LlI"
      }
    }
  ]
}